# NÃ­vel 5: MÃ©tricas de Agentes

Sistema de monitoramento para workflows multiagente.

---

## ğŸ“Š MÃ©tricas Coletadas

### 1. Por Skill (Subagente):

- **Tokens consumidos** - Total de tokens usados por cada Skill
- **Tempo de execuÃ§Ã£o** - DuraÃ§Ã£o mÃ©dia por chamada
- **Taxa de sucesso** - % de execuÃ§Ãµes bem-sucedidas
- **Erros comuns** - PadrÃµes de falha identificados

**Exemplo:**

```json
{
  "skill": "clean-code",
  "calls": 234,
  "tokens": 1200000,
  "avg_duration": 3.2,
  "success_rate": 0.94,
  "cost_usd": 18.5
}
```

### 2. Por Workflow:

- **Custo total** - Tokens Ã— pricing
- **LatÃªncia ponta-a-ponta** - Tempo total do workflow
- **Handoffs realizados** - NÃºmero de delegaÃ§Ãµes
- **Qualidade do cÃ³digo** - Taxa de aprovaÃ§Ã£o em reviews

**Exemplo:**

```json
{
  "workflow": "feature-authentication",
  "skills_used": [
    "backend-dev-guidelines",
    "react-patterns",
    "security-review"
  ],
  "total_tokens": 45000,
  "duration": 420,
  "handoffs": 3,
  "cost_usd": 2.35
}
```

### 3. Por Projeto:

- **Skills mais usadas** - Ranking de utilizaÃ§Ã£o
- **PadrÃµes de delegaÃ§Ã£o** - CombinaÃ§Ãµes comuns
- **ROI** - Tempo economizado vs custo
- **EvoluÃ§Ã£o de qualidade** - TendÃªncia temporal

**Exemplo:**

```markdown
## Projeto: Cursor-IDE

- Total de chamadas: 1,234
- Skills favoritas: clean-code (234), react-patterns (156)
- ROI: 2,674% (87h economizadas / $156.78 gastos)
- Qualidade: +15% vs mÃªs anterior
```

---

## ğŸ› ï¸ ImplementaÃ§Ã£o

### Arquitetura:

```
Cursor Agent
    â†“ (usa Skill)
metrics_tracker.py
    â†“ (log)
.cursor/data/metrics/YYYY-MM-DD.jsonl
    â†“ (agrega)
/metrics-report
    â†“ (gera)
Dashboard em Markdown
```

### Arquivos:

1. **Script de tracking**: `.cursor/scripts/metrics_tracker.py`
2. **Logs diÃ¡rios**: `.cursor/data/metrics/YYYY-MM-DD.jsonl`
3. **Comando de relatÃ³rio**: `.cursor/Commands/metrics-report.md`
4. **Dashboard**: `.cursor/docs/metrics-dashboard.md` (gerado)

---

## ğŸ“ˆ Como Usar

### 1. Logging AutomÃ¡tico

O sistema registra automaticamente cada vez que uma Skill Ã© usada:

```python
# Interno do Cursor (pseudo-cÃ³digo)
def use_skill(skill_name, context):
    start_time = time.now()
    tokens_start = get_token_count()

    result = execute_skill(skill_name, context)

    tokens_used = get_token_count() - tokens_start
    duration = time.now() - start_time

    metrics_tracker.log_skill_usage(
        skill_name=skill_name,
        tokens=tokens_used,
        duration=duration,
        success=result.success
    )

    return result
```

### 2. Gerar RelatÃ³rio

Execute no chat do Cursor:

```
/metrics-report week
```

Ou:

```
/metrics-report month
/metrics-report project
```

### 3. Visualizar Dashboard

RelatÃ³rio gerado em: `.cursor/docs/metrics-dashboard.md`

---

## ğŸ“Š Exemplo de RelatÃ³rio

```markdown
# RelatÃ³rio de MÃ©tricas - Semana 20-26/01/2026

## ğŸ“ˆ VisÃ£o Geral

- **Total de operaÃ§Ãµes**: 567
- **Skills Ãºnicas usadas**: 18
- **Tokens consumidos**: 3.2M
- **Custo total**: $62.45
- **Tempo total de execuÃ§Ã£o**: 4.2h

## ğŸ† Top 5 Skills Mais Usadas

1. **@clean-code**: 234 chamadas, 1.2M tokens, $18.50
   - Taxa de sucesso: 94%
   - DuraÃ§Ã£o mÃ©dia: 3.2s
2. **@react-patterns**: 156 chamadas, 890K tokens, $13.35
   - Taxa de sucesso: 91%
   - DuraÃ§Ã£o mÃ©dia: 4.1s
3. **@backend-dev-guidelines**: 98 chamadas, 670K tokens, $10.05
   - Taxa de sucesso: 96%
   - DuraÃ§Ã£o mÃ©dia: 5.8s

## ğŸ”„ EficiÃªncia de Handoffs

- **Total de handoffs**: 45
- **MÃ©dia de subagentes por task**: 2.3
- **ReduÃ§Ã£o de contexto**: 67% vs abordagem monolÃ­tica

## âœ… Qualidade do CÃ³digo

- **Taxa de aprovaÃ§Ã£o em /code-review**: 89%
- **Bugs encontrados pÃ³s-deploy**: 3 (vs 12 mÃªs anterior)
- **Cobertura de testes**: 87% (+12% vs mÃªs anterior)

## ğŸ’° ROI Estimado

- **Horas economizadas**: 87h (baseado em velocidade mÃ©dia)
- **Custo em tokens**: $62.45
- **Valor/hora** (assumindo $50/h): $4,350
- **ROI**: 2,674%

## ğŸ“Š PadrÃµes de Uso

### CombinaÃ§Ãµes Comuns:

1. `@backend-dev-guidelines` â†’ `@clean-code` â†’ `/code-review` (28x)
2. `@react-patterns` â†’ `@frontend-design` â†’ `/code-review` (22x)
3. `/handoff` â†’ mÃºltiplas Skills â†’ `/test-fix-all` (15x)

### Workflows de Sucesso:

- **Feature completa**: 4.2 Skills em mÃ©dia, 95% sucesso
- **RefatoraÃ§Ã£o**: 2.8 Skills em mÃ©dia, 91% sucesso
- **Bug fix**: 1.9 Skills em mÃ©dia, 87% sucesso
```

---

## ğŸ¯ Objetivos das MÃ©tricas

1. **OtimizaÃ§Ã£o de custos** - Identificar Skills caras vs valor
2. **Melhoria de qualidade** - Tracking de sucesso/falhas
3. **Previsibilidade** - Estimativas mais precisas
4. **ROI** - Justificar investimento em IA

---

## ğŸ”§ ConfiguraÃ§Ã£o AvanÃ§ada

### Ajustar pricing:

Edite `.cursor/scripts/metrics_tracker.py`:

```python
def calculate_cost(self, tokens):
    # Pricing: Claude Sonnet 4.5
    input_cost = 0.003  # per 1K tokens
    output_cost = 0.015  # per 1K tokens
    return (tokens / 1000) * ((input_cost + output_cost) / 2)
```

### Adicionar mÃ©tricas customizadas:

```python
def log_custom_metric(self, metric_name, value):
    entry = {
        "timestamp": datetime.now().isoformat(),
        "metric": metric_name,
        "value": value
    }
    # Log to custom file
```

---

## ğŸ“š IntegraÃ§Ã£o com Obsidian

Sincronize relatÃ³rios para Obsidian:

```
/metrics-report week â†’ .cursor/docs/metrics-dashboard.md
                     â†“
           /sync-docs-obsidian
                     â†“
           Obsidian/Metrics/week-26-01-2026.md
```

Visualize evoluÃ§Ã£o no Obsidian graph view!

---

## ğŸš€ PrÃ³ximos Passos

1. âœ… Execute cÃ³digo pela primeira vez para iniciar logging
2. âœ… ApÃ³s 1 semana, gere primeiro relatÃ³rio
3. âœ… Analise padrÃµes de uso
4. âœ… Otimize workflows baseado em mÃ©tricas
5. âœ… Itere e melhore continuamente

---

**Status**: Sistema de mÃ©tricas pronto para uso! ğŸ“Š
